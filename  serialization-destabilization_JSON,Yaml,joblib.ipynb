{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialization and deserialization using JSON, pickl, yaml and joblib\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json Searilizing and Desearilizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"1\": \"ML model deploy\", \"2\": \"DL model deployment\", \"3\": \"NLP model deployment\"}\n",
      "[11, 22, 33]\n",
      "null\n",
      "true\n"
     ]
    }
   ],
   "source": [
    "# Searilizing JSON \n",
    "\n",
    "import json\n",
    "\n",
    "# A dictionary of model deployments \n",
    "\n",
    "Dict = {\n",
    "        1:\"ML model deploy\",\n",
    "\n",
    "        2:\"DL model deployment\",\n",
    "\n",
    "        3:\"NLP model deployment\",\n",
    "        }              \n",
    "\n",
    "jsonString  = json.dumps(Dict)\n",
    "# A python dictionary as a JSON string\n",
    "print(jsonString)\n",
    "# A list as JSON\n",
    "repDigits = [11,22,33]\n",
    "jsonString  = json.dumps(repDigits)\n",
    "# A python list as a JSON string\n",
    "print(jsonString)\n",
    "# Print None as JSON\n",
    "reference1 = None\n",
    "jsonString  = json.dumps(reference1)\n",
    "print(jsonString)\n",
    "# Print True as JSON\n",
    "alive = True\n",
    "jsonString  = json.dumps(alive)\n",
    "print(jsonString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary\n",
    "Python and the json module is working extremely well with dictionaries. \n",
    "The following is for serializing and deserializing a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": \"DT\",\n",
      "  \"name\": \"Model\"\n",
      "}\n",
      "{'model': 'DT', 'name': 'Model'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "machine_learning = {\n",
    "    \"model\": \"DT\",\n",
    "    \"name\": \"Model\"\n",
    "}\n",
    "json_data = json.dumps(machine_learning, indent=2)\n",
    "print(json_data)\n",
    "print(json.loads(json_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object\n",
    "However, if we create an object, e.g. machine_learning (below), it doesn’t work out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"select_model\": \"DL\", \"name\": \"Doyle\"}\n",
      "<__main__.machine_learning object at 0x000000F0E34162B0>\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "# class Student(object):\n",
    "#     def __init__(self, first_name: str, last_name: str):\n",
    "#         self.first_name = first_name\n",
    "#         self.last_name = last_name\n",
    "#         \n",
    "# student = Student(first_name=\"Jake\", last_name=\"Doyle\")\n",
    "# json_data = json.dumps(student.__dict__)\n",
    "# print(json_data)\n",
    "# print(Student(**json.loads(json_data)))\n",
    "# \n",
    "\n",
    "import json\n",
    "class machine_learning(object):\n",
    "    def __init__(self, select_model: str, name: str):\n",
    "        self.select_model =select_model\n",
    "        self.name = name\n",
    "        \n",
    "student = machine_learning(select_model=\"DL\", name=\"Doyle\")\n",
    "json_data = json.dumps(student.__dict__)\n",
    "print(json_data)\n",
    "print(machine_learning(**json.loads(json_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.machine_learning at 0xf0e33e8f98>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ** is to expanding the dictionary\n",
    "# just like \n",
    "d = json.loads(json_data)\n",
    "machine_learning(select_model=d[\"select_model\"], name=d[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json complex Objects\n",
    "Things get tricky with complex objects. Now assume that we have a Team object, which contains a list of Employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"employees\": [\n",
      "        {\n",
      "            \"first_name\": \"Asha\",\n",
      "            \"last_name\": \"icy\"\n",
      "        },\n",
      "        {\n",
      "            \"first_name\": \"Veera\",\n",
      "            \"last_name\": \"Ganesh\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "<__main__.Team object at 0x000000A75D4B7358>\n",
      "[<__main__.Employee object at 0x000000A75D4B7208>, <__main__.Employee object at 0x000000A75D4B7470>]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import json\n",
    "class Employee(object):\n",
    "    def __init__(self, first_name: str, last_name: str):\n",
    "        self.first_name = first_name\n",
    "        self.last_name = last_name\n",
    "    @classmethod\n",
    "    def from_json(cls, data):\n",
    "        return cls(**data)\n",
    "class Team(object):\n",
    "    def __init__(self, employees: List[Employee]):\n",
    "        self.employees = employees\n",
    "    @classmethod\n",
    "    def from_json(cls, data):\n",
    "        employees = list(map(Employee.from_json, data[\"employees\"]))\n",
    "        return cls(employees)\n",
    "employee1 = Employee(first_name=\"Asha\", last_name=\"icy\")\n",
    "employee2 = Employee(first_name=\"Veera\", last_name=\"Ganesh\")\n",
    "team = Team(employees=[employee1, employee2])\n",
    "# Serializing\n",
    "data = json.dumps(team, default=lambda o: o.__dict__, sort_keys=True, indent=4)\n",
    "print(data)\n",
    "# Deserializing\n",
    "decoded_team = Team.from_json(json.loads(data))\n",
    "print(decoded_team)\n",
    "print(decoded_team.employees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YAML Searilizing and Desearilizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaml in c:\\users\\asha.ponnada\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (20.4.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\asha.ponnada\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pyaml) (3.13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\asha.ponnada\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "Installation in pyhton\n",
    "\n",
    "!pip install pyaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML may be the most human friendly data serialization standard for all programming languages.\n",
    "\n",
    "Python yaml module is called pyaml\n",
    "\n",
    "YAML is an alternative to JSON −\n",
    "\n",
    "Human readable code − YAML is the most human readable format so much so that even its front-page content is displayed in YAML to make this point.\n",
    "\n",
    "Compact code − In YAML we use whitespace indentation to denote structure not brackets.\n",
    "\n",
    "Syntax for relational data − For internal references we use anchors (&) and aliases (*).\n",
    "\n",
    "One of the area where it is used widely is for viewing/editing of data structures − for example configuration files, dumping during debugging and document headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 100\n",
      "b: 300\n",
      "\n",
      "- 1\n",
      "- 2\n",
      "\n",
      "!!python/tuple\n",
      "- x\n",
      "- y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "dict1={'a':100, 'b': 300}\n",
    "list1 = [1,2]\n",
    "tuple1 = ('x','y')\n",
    "print(yaml.dump(dict1,default_flow_style=False))\n",
    "print(yaml.dump(list1,default_flow_style=False))\n",
    "print(yaml.dump(tuple1,default_flow_style = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serialized_user:  {name: spam, surname: eggs}\n",
      "name: spam, sname: eggs\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "class User(object):\n",
    "    def __init__(self, name, surname):\n",
    "        self.name= name\n",
    "        self.surname= surname\n",
    "\n",
    "    def yaml(self):\n",
    "        return yaml.dump(self.__dict__)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(data):\n",
    "        values = yaml.safe_load(data)\n",
    "        return User(values[\"name\"], values[\"surname\"])\n",
    "\n",
    "user = User('spam', 'eggs')\n",
    "serialized_user = user.yaml()\n",
    "print(\"serialized_user:  %s\" % serialized_user.strip())\n",
    "\n",
    "#Network\n",
    "deserialized_user = User.load(serialized_user)\n",
    "print(\"name: %s, sname: %s\" % (deserialized_user.name, deserialized_user.surname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save Yaml files as  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######### items.yaml\n",
    "\n",
    "# raincoat: 1\n",
    "# coins: 5\n",
    "# books: 23\n",
    "# spectacles: 2\n",
    "# chairs: 12\n",
    "# pens: 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########  data.yamal\n",
    "# \n",
    "# cities:\n",
    "#   - Bratislava\n",
    "#   - Kosice\n",
    "#   - Trnava\n",
    "#   - Moldava\n",
    "#   - Trencin\n",
    "# ---\n",
    "# companies:\n",
    "#   - Eset\n",
    "#   - Slovnaft\n",
    "#   - Duslo Sala\n",
    "#   - Matador Puchov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.13'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyYAML\n",
      "  Downloading PyYAML-5.3.1-cp37-cp37m-win_amd64.whl (216 kB)\n",
      "Installing collected packages: PyYAML\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: awscli 1.16.137 has requirement botocore==1.12.127, but you'll have botocore 1.14.7 which is incompatible.\n",
      "ERROR: awscli 1.16.137 has requirement PyYAML<=3.13,>=3.10, but you'll have pyyaml 5.3.1 which is incompatible.\n",
      "ERROR: awscli 1.16.137 has requirement s3transfer<0.3.0,>=0.2.0, but you'll have s3transfer 0.3.1 which is incompatible.\n",
      "ERROR: docker-compose 1.24.0 has requirement colorama<0.5,>=0.4; sys_platform == \"win32\", but you'll have colorama 0.3.9 which is incompatible.\n",
      "ERROR: docker-compose 1.24.0 has requirement PyYAML<4.3,>=3.10, but you'll have pyyaml 5.3.1 which is incompatible.\n",
      "ERROR: docker-compose 1.24.0 has requirement requests!=2.11.0,!=2.12.2,!=2.18.0,<2.21,>=2.6.1, but you'll have requests 2.22.0 which is incompatible.\n",
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'C:\\\\Users\\\\ASHA~1.PON\\\\AppData\\\\Local\\\\Temp\\\\pip-uninstall-kfvfqe76\\\\_yaml.cp37-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\asha.ponnada\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U PyYAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raincoat': 1,\n",
       " 'coins': 5,\n",
       " 'books': 23,\n",
       " 'spectacles': 2,\n",
       " 'chairs': 12,\n",
       " 'pens': 6}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "with open('items.yaml') as parameters:\n",
    "    my_dict = yaml.safe_load(parameters)\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python YAML dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- {name: John Doe, occupation: gardener}\n",
      "- {name: Lucy Black, occupation: teacher}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "users = [{'name': 'John Doe', 'occupation': 'gardener'},\n",
    "         {'name': 'Lucy Black', 'occupation': 'teacher'}]\n",
    "\n",
    "print(yaml.dump(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python YAML write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "users = [{'name': 'John Doe', 'occupation': 'gardener'},\n",
    "         {'name': 'Lucy Black', 'occupation': 'teacher'}]\n",
    "\n",
    "with open('users.yaml', 'w') as f:\n",
    "    \n",
    "    data = yaml.dump(users, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle - Serialization and deserialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insatalation\n",
    "pip insatll pickle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling- Example - will store in book file \n",
    "\n",
    "dogs_dict = { 'MLbooks': 3, 'DLbooks': 8, 'Dsbooks': 5 }\n",
    "filename = 'books'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(dogs_dict,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickling files\n",
    "# The process of loading a pickled file back into a Python program is similar to the one you \n",
    "# saw previously: use the open() function again, but this time with 'rb' as second argument\n",
    "# (instead of wb). The r stands for read mode and the b stands for binary mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MLbooks': 3, 'DLbooks': 8, 'Dsbooks': 5}\n",
      "True\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Unpickling\n",
    "infile = open(filename,'rb')\n",
    "new_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "print(new_dict)\n",
    "print(new_dict==dogs_dict)\n",
    "print(type(new_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asha => {'key': 'ash_123', 'name': 'Asha', 'age': 34, 'pay': 40000}\n",
      "Veera => {'key': 'vee_123', 'name': 'Veera', 'age': 37, 'pay': 50000}\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "  \n",
    "def employeedata(): \n",
    "    # initializing data to be stored in db \n",
    "    Asha = {'key' : 'ash_123', 'name' : 'Asha','age' : 34, 'pay' : 40000} \n",
    "    Veera = {'key' : 'vee_123', 'name' : 'Veera','age' : 37, 'pay' : 50000} \n",
    "  \n",
    "    # database \n",
    "    db = {} \n",
    "    db['Asha'] =Asha\n",
    "    db['Veera'] = Veera\n",
    "      \n",
    "    # Its important to use binary mode \n",
    "    dbfile = open('expickle', 'ab') \n",
    "      \n",
    "    # source, destination \n",
    "    pickle.dump(db, dbfile)                      \n",
    "    dbfile.close() \n",
    "  \n",
    "def loadData(): \n",
    "    # for reading also binary mode is important \n",
    "    dbfile = open('expickle', 'rb')      \n",
    "    db = pickle.load(dbfile) \n",
    "    for keys in db: \n",
    "        print(keys, '=>', db[keys]) \n",
    "    dbfile.close() \n",
    "  \n",
    "if __name__ == '__main__': \n",
    "    employeedata() \n",
    "    loadData() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', [1, 2, 3]), ('b', array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create an object\n",
    "import numpy as np\n",
    "to_persist = [('a', [1, 2, 3]), ('b', np.arange(10))]\n",
    "to_persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', [1, 2, 3]), ('b', array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saved into filename\n",
    "## create a file\n",
    "from tempfile import mkdtemp\n",
    "savedir = mkdtemp()\n",
    "import os\n",
    "filename = os.path.join(savedir, 'test.joblib')\n",
    "\n",
    "import joblib\n",
    "joblib.dump(to_persist, filename)  \n",
    "joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\ASHA~1.PON\\\\AppData\\\\Local\\\\Temp\\\\tmpntil5lqf\\\\test.joblib.compressed']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump() and joblib.load() functions also accept file\n",
    "with open(filename, 'wb') as file:  # doctest: +ELLIPSIS\n",
    "     joblib.dump(to_persist, file)\n",
    "with open(filename, 'rb') as file:  # doctest: +ELLIPSIS\n",
    "       joblib.load(file)\n",
    "joblib.dump(to_persist, filename + '.compressed', compress=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\ASHA~1.PON\\\\AppData\\\\Local\\\\Temp\\\\tmpntil5lqf\\\\test.joblib.z']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(to_persist, filename + '.z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
